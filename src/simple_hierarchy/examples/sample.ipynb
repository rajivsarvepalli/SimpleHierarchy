{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI_TtYxZ_MJC"
   },
   "source": [
    "# Getting Started with simple-hierarchy-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1Nd1Peg_Ufs",
    "outputId": "b93c1816-608b-4d85-b389-2d20d10c467d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simple-hierarchy-pytorch\n",
      "  Using cached simple_hierarchy_pytorch-0.0.1-py3-none-any.whl (8.9 kB)\n",
      "Requirement already satisfied: torch>=1.0 in c:\\users\\rajiv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from simple-hierarchy-pytorch) (1.7.0+cu101)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\rajiv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch>=1.0->simple-hierarchy-pytorch) (0.6)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rajiv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch>=1.0->simple-hierarchy-pytorch) (3.7.4.3)\n",
      "Requirement already satisfied: future in c:\\users\\rajiv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch>=1.0->simple-hierarchy-pytorch) (0.18.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\rajiv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch>=1.0->simple-hierarchy-pytorch) (1.17.1+mkl)\n",
      "Installing collected packages: simple-hierarchy-pytorch\n",
      "Successfully installed simple-hierarchy-pytorch-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install simple-hierarchy-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yw5jztdD_XIz"
   },
   "outputs": [],
   "source": [
    "from simple_hierarchy.hierarchal_model import HierarchalModel\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "jHCxRL-ef9Zd",
    "outputId": "2852e85f-2247-47e6-8c3d-8f4c3eff0df3"
   },
   "outputs": [],
   "source": [
    "hierarchy = {\n",
    "    (\"A\", 2) : [(\"B\", 5), (\"C\", 7)],\n",
    "    (\"H\", 2) : [(\"A\", 2), (\"K\", 7), (\"L\", 10)]\n",
    "}\n",
    "# first two layers are base model\n",
    "# last two are distinct per class\n",
    "model = HierarchalModel(model=nn.ModuleList([nn.Linear(10, 10) for i in range(4)]), k=2, hierarchy=hierarchy, size=(10,10,10))\n",
    "input = torch.rand((10,10))\n",
    "out = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1Ash67dzgdCH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H 2 [A 2 [B 5 [], C 7 []], K 7 [], L 10 []]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the model's tree\n",
    "model.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-YC3q1mAgffa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base layers\n",
    "model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NlFBN12ugh-c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (('H', 2)): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (3): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       "  (('A', 2)): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=10, bias=True)\n",
       "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (3): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       "  (('B', 5)): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=10, bias=True)\n",
       "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (3): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (('C', 7)): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=10, bias=True)\n",
       "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (3): Linear(in_features=10, out_features=7, bias=True)\n",
       "  )\n",
       "  (('K', 7)): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=10, bias=True)\n",
       "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (3): Linear(in_features=10, out_features=7, bias=True)\n",
       "  )\n",
       "  (('L', 10)): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=10, bias=True)\n",
       "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the layers that are distinct per class\n",
    "# the additional layers are to link together differing output sizes to the provided layers (two additional layers per class)\n",
    "# in a later version these may be customizable to the layers you want (should you want to proivde distinct aspects of non-linear layers; currently requires conversion into linear layers) \n",
    "model.last_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UJNrkMeThHjs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('H', 2)  :  torch.Size([10, 2])\n",
      "('A', 2)  :  torch.Size([10, 2])\n",
      "('B', 5)  :  torch.Size([10, 5])\n",
      "('C', 7)  :  torch.Size([10, 7])\n",
      "('K', 7)  :  torch.Size([10, 7])\n",
      "('L', 10)  :  torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "# output order and shape (order is defined through parameter output_order)\n",
    "for o, a in zip(out, model.output_order):\n",
    "  print(a, \" : \", o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAMzRo8nXnVh"
   },
   "source": [
    "# Class Hierarchy  Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5mm_DMpXw3T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from itertools import chain\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNW1jBjl1bMU"
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "  def __init__(self, name, n_classes, parent):\n",
    "      self.n_classes = n_classes\n",
    "      self.name = name\n",
    "      self.children = []\n",
    "      self.parent = parent\n",
    "\n",
    "  def add_child(self, child):\n",
    "      self.children.append(child)\n",
    "  def __repr__(self) -> str:\n",
    "    return str(self.name) + \" \" + str(self.n_classes) + \" \" + str(self.children)\n",
    "  def get_tuple(self):\n",
    "    return (self.name, self.n_classes)\n",
    "  def __iter__(self):\n",
    "    isingle = lambda x : (yield x)\n",
    "    return chain(*([isingle(self)] + list(map(iter, self.children))))\n",
    "\n",
    "class Tree(object):\n",
    "  def __init__(self, root : Node):\n",
    "      self.root = root\n",
    "  def __repr__(self):\n",
    "    return self.root.__repr__()\n",
    "  def __iter__(self):\n",
    "    return iter(self.root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwH2JAs82gyD"
   },
   "outputs": [],
   "source": [
    "hierarchy = {\n",
    "    (\"A\", 2) : [(\"B\", 5), (\"C\", 7)],\n",
    "    (\"H\", 2) : [(\"A\", 2), (\"K\", 7), (\"L\", 10)]\n",
    "}\n",
    "\n",
    "def to_tree(hierarchy, root_node):\n",
    "  root = root_node.get_tuple()\n",
    "  for i, (node, children) in list(enumerate(hierarchy.items())):\n",
    "    if root == node:\n",
    "      for c in children:\n",
    "        child = Node(*c, root_node)\n",
    "        root_node.add_child(child)\n",
    "        to_tree(hierarchy, child)\n",
    "  if root in hierarchy:\n",
    "    hierarchy.pop(root)\n",
    "\n",
    "def hierarchy_to_tree(hierarchy : Dict[Tuple, Tuple]):\n",
    "  all_children = list()\n",
    "  for i, ((parent, n_classes1), children) in enumerate(hierarchy.items()):\n",
    "    all_children.extend(children)\n",
    "  found_root = False\n",
    "  root = None\n",
    "  for i, (node, children) in enumerate(hierarchy.items()):\n",
    "    if node not in all_children:\n",
    "\n",
    "      root = node\n",
    "      if found_root:\n",
    "        raise ValueError(\"Invalid hierarchy tree.\")\n",
    "      found_root = True\n",
    "  root_node = Node(root[0], root[1], None)\n",
    "  hier = hierarchy.copy()\n",
    "  to_tree(hier, root_node)\n",
    "  return Tree(root_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yk17kuPZ9xoT",
    "outputId": "14458f77-3415-4943-f795-917b9e49e9a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H 2 [A 2 [B 5 [], C 7 []], K 7 [], L 10 []]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = hierarchy_to_tree(hierarchy)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-2Jr0uHjikv",
    "outputId": "83f8da28-304a-4078-f65c-1cebe7fbf63b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 2 [B 3 [D 3 []], C 5 []]\n"
     ]
    }
   ],
   "source": [
    "root = Node('A', 2, None)\n",
    "child1 = Node('B', 3, root)\n",
    "child2 = Node('C', 5, root)\n",
    "child_of_child = Node('D', 3, child1)\n",
    "root.add_child(child1)\n",
    "root.add_child(child2)\n",
    "child1.add_child(child_of_child)\n",
    "tree = Tree(root)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_LlnT_oSA10",
    "outputId": "701399fb-0567-408d-f07c-0b0436be66ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H 2 [A 2 [B 5 [], C 7 []], K 7 [], L 10 []]\n",
      "A 2 [B 5 [], C 7 []]\n",
      "B 5 []\n",
      "C 7 []\n",
      "K 7 []\n",
      "L 10 []\n"
     ]
    }
   ],
   "source": [
    "for t in tree:\n",
    "  print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzC_zi4GXmbK"
   },
   "outputs": [],
   "source": [
    "class HierarchalModel(torch.nn.Module):\n",
    "  def __init__(self, hierarchy : Dict[Tuple, Tuple], size : int, \n",
    "               output_order: Optional[List] = None, base_model: Optional = None, model: Optional[nn.ModuleList] = None, \n",
    "               k: Optional[int] = 0, dim_to_concat: Optional[int] = None):\n",
    "    super(HierarchalModel, self).__init__()\n",
    "    if base_model:\n",
    "      self.base_model = base_model\n",
    "    else:\n",
    "      self.base_model = nn.Sequential(*model[0:len(model) - k])\n",
    "    self.last_layers = dict()\n",
    "    self.tree = hierarchy_to_tree(hierarchy)\n",
    "    self.output_order = output_order\n",
    "    if dim_to_concat:\n",
    "      self.dim_to_concat = dim_to_concat\n",
    "    else:\n",
    "      self.dim_to_concat = 1\n",
    "    for node in self.tree:\n",
    "      if model:\n",
    "        layer1 = model[len(model) - k: len(model)]\n",
    "      else:\n",
    "        layer1 = nn.ModuleList()\n",
    "      if node.parent:\n",
    "        n_classes1 = node.parent.n_classes\n",
    "      else:\n",
    "        n_classes1 = 0\n",
    "      n_classes2 = node.n_classes\n",
    "      \n",
    "      layers = nn.ModuleList()\n",
    "      layers.append(torch.nn.Linear(size[0] + n_classes1, size[1]))\n",
    "      layers.extend(layer1)\n",
    "      layers.append(torch.nn.Linear(size[2], n_classes2))\n",
    "      self.last_layers[str(node.get_tuple())] = nn.Sequential(*layers)\n",
    "    self.last_layers = nn.ModuleDict(self.last_layers)\n",
    "  def forward(self, x):\n",
    "    x = self.base_model(x)\n",
    "    # enumerate over a tree concating parents output into children outs\n",
    "    output_temp = dict()\n",
    "    for node in self.tree:\n",
    "      if node.parent:\n",
    "        parent_out = output_temp[node.parent.get_tuple()]\n",
    "\n",
    "        end_input = torch.cat((parent_out,x), self.dim_to_concat)\n",
    "        output_temp[node.get_tuple()] = self.last_layers[str(node.get_tuple())](end_input)\n",
    "      else:\n",
    "        output_temp[node.get_tuple()] = self.last_layers[str(node.get_tuple())](x)\n",
    "    outputs = list()\n",
    "    if not self.output_order:\n",
    "      self.output_order = output_temp.keys()\n",
    "    for o in self.output_order:\n",
    "      outputs.append(output_temp[o])\n",
    "    return tuple(outputs)\n",
    "\n",
    "\n",
    "  def hierarchy_to_tree(self, hierarchy : Dict[Tuple, Tuple]):\n",
    "    all_children = list()\n",
    "    for i, ((parent, n_classes1), children) in enumerate(hierarchy.items()):\n",
    "      all_children.extend(children)\n",
    "    found_root = False\n",
    "    root = None\n",
    "    for i, (node, children) in enumerate(hierarchy.items()):\n",
    "      if node not in all_children:\n",
    "        root = node\n",
    "        if found_root:\n",
    "          raise ValueError(\"Invalid hierarchy tree.\")\n",
    "        found_root = True\n",
    "    root_node = Node(root[0], root[1], None)\n",
    "    hier = hierarchy.copy()\n",
    "    to_tree(hier, root_node)\n",
    "    return Tree(root_node)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vW6snfSXiryP"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dem6F136cv-"
   },
   "source": [
    "### Basic Testing of Singular Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5m6SdISdouH",
    "outputId": "cba115eb-2778-4258-d3a1-1ca2ddc1b7ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('H', 2)  :  torch.Size([10, 2])\n",
      "('A', 2)  :  torch.Size([10, 2])\n",
      "('B', 5)  :  torch.Size([10, 5])\n",
      "('C', 7)  :  torch.Size([10, 7])\n",
      "('K', 7)  :  torch.Size([10, 7])\n",
      "('L', 10)  :  torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "model = HierarchalModel(model=nn.ModuleList([nn.Linear(10, 10) for i in range(2)]), k=1, hierarchy=hierarchy, size=(10,10,10))\n",
    "input = torch.rand((10,10))\n",
    "out = model(input)\n",
    "for o, a in zip(out, model.output_order):\n",
    "  print(a, \" : \", o.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vBa74W5irL2",
    "outputId": "46ec0af4-3263-4d85-a615-7c6a9c581b46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H 2 [A 2 [B 5 [], C 7 []], K 7 [], L 10 []]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cd3e3wYayE__",
    "outputId": "8b77549c-0c64-4691-c3b5-379c6fae0877"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H 2 [A 2 [B 5 [], C 7 []], K 7 [], L 10 []]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsE3n7O15lgo"
   },
   "source": [
    "## Example\n",
    "Let use consider the case of dataset with data from three different cities.\n",
    "In each city are 5 county and in each county there are 7 districts. Therefore we define a simple heirarchy $A$ (city) -> $B$ (county) -> $C$(district) where $A$ is of size $n, 3$, $B$ of $n, 5$, and C of $n, 7$. The following example will illustrate this example in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpCcF1pq65sp"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class RegionDataset(Dataset):\n",
    "  def __init__(self, length=100, transform=None):\n",
    "        \"\"\"\n",
    "        Example hierarchal dataset using random data. Data is of size 3 x 36 x 36 mimicking an image dataset.\n",
    "        Args:\n",
    "            length (int, optional): Size of dataset.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.length = length\n",
    "        self.transform = transform\n",
    "        self.data = torch.rand(length, 3, 36, 36)\n",
    "        self.labelA = torch.randint(0, 2, (length,))\n",
    "        self.labelB = torch.randint(0, 5, (length,))\n",
    "        self.labelC = torch.randint(0, 7, (length,))\n",
    "  def __len__(self):\n",
    "      return self.length\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      if torch.is_tensor(idx):\n",
    "        idx = idx.tolist()\n",
    "      sample = self.data[idx]\n",
    "      labelA = self.labelA[idx]\n",
    "      labelB = self.labelB[idx]\n",
    "      labelC = self.labelC[idx]\n",
    "      if self.transform:\n",
    "          sample = self.transform(sample)\n",
    "\n",
    "      return sample, labelA, labelB, labelC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDMKhekK9LIO"
   },
   "outputs": [],
   "source": [
    "dataset = RegionDataset(length=1000)\n",
    "percent_train = 0.8\n",
    "train_size = int(0.8*len(dataset))\n",
    "val_size = int(len(dataset) - train_size)\n",
    "trainset_t, valset_t = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "example_dataset = {'train': trainset_t, \n",
    "                  'val' : valset_t}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(example_dataset[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(example_dataset[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6DZsC9g9EPH"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, nepochs, dataset_sizes):\n",
    "    start_time = time.time()\n",
    "    best_model_val = copy.deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(nepochs):\n",
    "        print('Epoch {}/{}'.format(epoch, nepochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for ph in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_correctsA = 0\n",
    "            running_correctsB = 0\n",
    "            running_correctsC = 0\n",
    "            if ph == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            for inputs, labelA, labelB, labelC in dataloaders[ph]:\n",
    "\n",
    "                # zero per epoch\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(ph == 'train'):\n",
    "                    outputA, outputB, outputC = model(inputs)\n",
    "\n",
    "                    _, predsA = torch.max(outputA, 1)\n",
    "                    _, predsB = torch.max(outputB, 1)\n",
    "                    _, predsC = torch.max(outputC, 1)\n",
    "                    loss = criterion(outputA, labelA) + criterion(outputB, labelB) + criterion(outputC, labelC)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if ph == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += float(loss.item() * inputs.size(0))\n",
    "\n",
    "\n",
    "                running_correctsA += torch.sum(predsA == labelA.data)\n",
    "                running_correctsB += torch.sum(predsB == labelB.data)\n",
    "                running_correctsC += torch.sum(predsC == labelC.data)\n",
    "                \n",
    "            if ph == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            e_loss = running_loss / dataset_sizes[ph]\n",
    "            epoch_acc = (running_correctsA.double() + running_correctsB.double() + running_correctsC.double())/  (3 * dataset_sizes[ph])\n",
    "            print(\"Accuracy A {:.4f}, Accuracy B {:.4f}, Accuracy C {:.4f}\".format(running_correctsA.double()/dataset_sizes[ph], \n",
    "                                                                                   running_correctsB.double()/dataset_sizes[ph], \n",
    "                                                                                   running_correctsC.double()/dataset_sizes[ph]))\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                ph, e_loss, epoch_acc))\n",
    "            # save best val accuracy\n",
    "            if ph == 'val' and epoch_acc > best_val_acc:\n",
    "                best_val_acc = epoch_acc\n",
    "                best_model_val = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_val_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_val)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Crxq2pFB_m3q",
    "outputId": "b2a09667-d3d4-4678-e684-b45da7544ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "Accuracy A 0.5262, Accuracy B 0.1875, Accuracy C 0.1275\n",
      "train Loss: 4.2603 Acc: 0.2804\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1400\n",
      "val Loss: 4.2598 Acc: 0.2767\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1275\n",
      "train Loss: 4.2592 Acc: 0.2796\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1400\n",
      "val Loss: 4.2585 Acc: 0.2767\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1275\n",
      "train Loss: 4.2580 Acc: 0.2796\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1400\n",
      "val Loss: 4.2573 Acc: 0.2767\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1275\n",
      "train Loss: 4.2567 Acc: 0.2796\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1400\n",
      "val Loss: 4.2561 Acc: 0.2767\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1275\n",
      "train Loss: 4.2553 Acc: 0.2796\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1400\n",
      "val Loss: 4.2552 Acc: 0.2767\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1275\n",
      "train Loss: 4.2543 Acc: 0.2796\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1400\n",
      "val Loss: 4.2544 Acc: 0.2767\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1275\n",
      "train Loss: 4.2533 Acc: 0.2796\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1400\n",
      "val Loss: 4.2534 Acc: 0.2767\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1275\n",
      "train Loss: 4.2523 Acc: 0.2796\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1400\n",
      "val Loss: 4.2525 Acc: 0.2767\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1275\n",
      "train Loss: 4.2515 Acc: 0.2796\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1400\n",
      "val Loss: 4.2517 Acc: 0.2767\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1288\n",
      "train Loss: 4.2508 Acc: 0.2800\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1400\n",
      "val Loss: 4.2510 Acc: 0.2767\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1263\n",
      "train Loss: 4.2502 Acc: 0.2792\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1550\n",
      "val Loss: 4.2510 Acc: 0.2817\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1275\n",
      "train Loss: 4.2501 Acc: 0.2796\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1600\n",
      "val Loss: 4.2509 Acc: 0.2833\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1275\n",
      "train Loss: 4.2500 Acc: 0.2796\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1600\n",
      "val Loss: 4.2509 Acc: 0.2833\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1300\n",
      "train Loss: 4.2500 Acc: 0.2804\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1600\n",
      "val Loss: 4.2508 Acc: 0.2833\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1325\n",
      "train Loss: 4.2499 Acc: 0.2812\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1700\n",
      "val Loss: 4.2507 Acc: 0.2867\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1363\n",
      "train Loss: 4.2498 Acc: 0.2825\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1800\n",
      "val Loss: 4.2507 Acc: 0.2900\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1363\n",
      "train Loss: 4.2498 Acc: 0.2825\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1800\n",
      "val Loss: 4.2506 Acc: 0.2900\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1375\n",
      "train Loss: 4.2497 Acc: 0.2829\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1750\n",
      "val Loss: 4.2506 Acc: 0.2883\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1388\n",
      "train Loss: 4.2496 Acc: 0.2833\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1750\n",
      "val Loss: 4.2505 Acc: 0.2883\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "Accuracy A 0.5238, Accuracy B 0.1875, Accuracy C 0.1437\n",
      "train Loss: 4.2496 Acc: 0.2850\n",
      "Accuracy A 0.5100, Accuracy B 0.1800, Accuracy C 0.1700\n",
      "val Loss: 4.2504 Acc: 0.2867\n",
      "\n",
      "Training complete in 0m 8s\n",
      "Best val Acc: 0.290000\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "\n",
    "nepochs = 20\n",
    "nclasses = 20\n",
    "lr = 0.001\n",
    "model_base = nn.Sequential(\n",
    "  nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5), \n",
    "  nn.ReLU(), \n",
    "  nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "  nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5), \n",
    "  nn.ReLU(), \n",
    "  nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "  nn.Flatten(start_dim=1), \n",
    "  nn.Linear(in_features=576, out_features=120), \n",
    "  nn.ReLU(), \n",
    "  nn.Linear(in_features=120, out_features=84), \n",
    "  nn.ReLU()\n",
    ")\n",
    "\n",
    "hierarchy = {\n",
    "    ('A', 2) : [('B', 5)],\n",
    "    ('B', 5) : [('C', 7)]\n",
    "}\n",
    "model = HierarchalModel(hierarchy, (84, 32, 32),base_model=model_base, dim_to_concat=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "model_fully_trained = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       nepochs, dataset_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldm7VUKtPCqs"
   },
   "source": [
    "Accuracy is not great but the concept is there and works. The data we are using does not make that much sense (random numbers representing an integer), so the network struggles to find connections between random labels and random \"images\". This is unsurpising and to be expected. The example merely illusrate how to use this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL2thpq6i5Id"
   },
   "source": [
    "## Model Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nuOMB5Wi6km"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "model = HierarchalModel(model=nn.ModuleList([nn.Linear(10, 10) for i in range(2)]), k=1, hierarchy=hierarchy, size=(10,10,10))\n",
    "\n",
    "writer = SummaryWriter('runs/model_graph')\n",
    "\n",
    "writer.add_graph(model, input)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Class Hierarchy Models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
